# Configuration file for baseline loss experiments
# Supports: overfit testing, LR search, and full grid search...

general:
  # Default program arguments
  program_args:
    batch_size: 64
    user_corrected_max_per_batch: 4
    max_user_corrected_per_batch: 10 # Maximum corrected instances per batch before giving up
    validate_ds_size: 0.4  # Fraction of test set used for validation
    early_stopping_patience: 10  # Epochs without improvement before stopping
    accuracy_threshold: 0.95  # Stop grid search if this accuracy is reached
    output_filename: "experiments/baseline_default.csv"
    tensorboard_log_dir: "runs/baseline_experiment"

  # Default hyperparameters for grid search
  learning_rate: [0.01, 0.001, 0.0001]
  loss_type: ["balanced", "imbalanced"]
  lambda_weight: [1.0]  # Weight for user-corrected samples in BaselineBalancedLoss
  user_corrected_pool_size: [100]  # Number of pre-generated corrected instances

specific:
  # Quick sanity check: overfit on tiny dataset
  overfit_test:
    program_args:
      batch_size: 16
      user_corrected_max_per_batch: 4
      early_stopping_patience: 50  # Allow more epochs for overfitting
      accuracy_threshold: 0.99
      output_filename: "experiments/overfit_test.csv"
      tensorboard_log_dir: "runs/overfit_test"
      train_dataset_size: 100  # Use only 100 samples

    learning_rate: [0.01]
    loss_type: ["balanced", "imbalanced"]
    lambda_weight: [1.0]
    user_corrected_pool_size: [50]  # Small pool for testing

  # Find optimal learning rate with fixed other params
  lr_search_balanced:
    program_args:
      batch_size: 64
      user_corrected_max_per_batch: 4
      early_stopping_patience: 10
      accuracy_threshold: 0.95
      output_filename: "experiments/lr_search_balanced.csv"
      tensorboard_log_dir: "runs/lr_search_balanced"
      train_dataset_size: 1000  # Subset for faster iteration

    learning_rate: [1.e-08, 1.5998587196060573e-08, 2.5595479226995333e-08, 4.0949150623804276e-08, 6.551285568595509e-08, 1.0481131341546853e-07, 1.67683293681101e-07, 2.6826957952797275e-07, 4.2919342601287785e-07, 6.866488450042998e-07, 1.0985411419875572e-06, 1.757510624854793e-06, 2.811768697974231e-06, 4.498432668969444e-06, 7.196856730011529e-06, 1.1513953993264481e-05, 1.8420699693267162e-05, 2.94705170255181e-05, 4.71486636345739e-05, 7.543120063354622e-05, 0.00012067926406393288, 0.00019306977288832496, 0.0003088843596477485, 0.0004941713361323838, 0.0007906043210907702, 0.0012648552168552957, 0.0020235896477251557, 0.0032374575428176467, 0.005179474679231213, 0.008286427728546842, 0.013257113655901109, 0.021209508879201925, 0.0339322177189533, 0.054286754393238594, 0.08685113737513521, 0.13894954943731389, 0.22229964825261955, 0.35564803062231287, 0.5689866029018305, 0.9102981779915227, 1.4563484775012443, 2.329951810515372, 3.727593720314938, 5.963623316594637, 9.540954763499963, 15.264179671752364, 24.420530945486547, 39.06939937054621, 62.50551925273976, 100.0]
    loss_type: ["balanced"]  # Fix loss type
    user_corrected_pool_size: [100]

  lr_search_imbalanced:
    program_args:
      batch_size: 64
      user_corrected_max_per_batch: 4
      early_stopping_patience: 10
      accuracy_threshold: 0.95
      output_filename: "experiments/lr_search_imbalanced.csv"
      tensorboard_log_dir: "runs/lr_search_imbalanced"
      train_dataset_size: 1000  # Subset for faster iteration

    learning_rate: [1.0e-08, 1.5998587196060573e-08, 2.5595479226995333e-08, 4.0949150623804276e-08, 6.551285568595509e-08, 1.0481131341546853e-07, 1.67683293681101e-07, 2.6826957952797275e-07, 4.2919342601287785e-07, 6.866488450042998e-07, 1.0985411419875572e-06, 1.757510624854793e-06, 2.811768697974231e-06, 4.498432668969444e-06, 7.196856730011529e-06, 1.1513953993264481e-05, 1.8420699693267162e-05, 2.94705170255181e-05, 4.71486636345739e-05, 7.543120063354622e-05, 0.00012067926406393288, 0.00019306977288832496, 0.0003088843596477485, 0.0004941713361323838, 0.0007906043210907702, 0.0012648552168552957, 0.0020235896477251557, 0.0032374575428176467, 0.005179474679231213, 0.008286427728546842, 0.013257113655901109, 0.021209508879201925, 0.0339322177189533, 0.054286754393238594, 0.08685113737513521, 0.13894954943731389, 0.22229964825261955, 0.35564803062231287, 0.5689866029018305, 0.9102981779915227, 1.4563484775012443, 2.329951810515372, 3.727593720314938, 5.963623316594637, 9.540954763499963, 15.264179671752364, 24.420530945486547, 39.06939937054621, 62.50551925273976, 100.0]
    loss_type: ["imbalanced"]  # Fix loss type
    user_corrected_pool_size: [100]

  # Search over lambda weight (for BaselineBalancedLoss)
  lambda_search:
    program_args:
      batch_size: 64
      user_corrected_max_per_batch: 4
      early_stopping_patience: 10
      accuracy_threshold: 0.95
      output_filename: "experiments/lambda_search.csv"
      tensorboard_log_dir: "runs/lambda_search"
      train_dataset_size: 1000

    learning_rate: [0.001]  # Best LR from lr_search_balanced
    loss_type: ["balanced"]
    lambda_weight: [1.00000000e-08, 1.45082878e-08, 2.10490414e-08, 3.05385551e-08,
       4.43062146e-08, 6.42807312e-08, 9.32603347e-08, 1.35304777e-07,
       1.96304065e-07, 2.84803587e-07, 4.13201240e-07, 5.99484250e-07,
       8.69749003e-07, 1.26185688e-06, 1.83073828e-06, 2.65608778e-06,
       3.85352859e-06, 5.59081018e-06, 8.11130831e-06, 1.17681195e-05,
       1.70735265e-05, 2.47707636e-05, 3.59381366e-05, 5.21400829e-05,
       7.56463328e-05, 1.09749877e-04, 1.59228279e-04, 2.31012970e-04,
       3.35160265e-04, 4.86260158e-04, 7.05480231e-04, 1.02353102e-03,
       1.48496826e-03, 2.15443469e-03, 3.12571585e-03, 4.53487851e-03,
       6.57933225e-03, 9.54548457e-03, 1.38488637e-02, 2.00923300e-02,
       2.91505306e-02, 4.22924287e-02, 6.13590727e-02, 8.90215085e-02,
       1.29154967e-01, 1.87381742e-01, 2.71858824e-01, 3.94420606e-01,
       5.72236766e-01, 8.30217568e-01, 1.20450354e+00, 1.74752840e+00,
       2.53536449e+00, 3.67837977e+00, 5.33669923e+00, 7.74263683e+00,
       1.12332403e+01, 1.62975083e+01, 2.36448941e+01, 3.43046929e+01,
       4.97702356e+01, 7.22080902e+01, 1.04761575e+02, 1.51991108e+02,
       2.20513074e+02, 3.19926714e+02, 4.64158883e+02, 6.73415066e+02,
       9.77009957e+02, 1.41747416e+03, 2.05651231e+03, 2.98364724e+03,
       4.32876128e+03, 6.28029144e+03, 9.11162756e+03, 1.32194115e+04,
       1.91791026e+04, 2.78255940e+04, 4.03701726e+04, 5.85702082e+04,
       8.49753436e+04, 1.23284674e+05, 1.78864953e+05, 2.59502421e+05,
       3.76493581e+05, 5.46227722e+05, 7.92482898e+05, 1.14975700e+06,
       1.66810054e+06, 2.42012826e+06, 3.51119173e+06, 5.09413801e+06,
       7.39072203e+06, 1.07226722e+07, 1.55567614e+07, 2.25701972e+07,
       3.27454916e+07, 4.75081016e+07, 6.89261210e+07, 1.00000000e+08]
    user_corrected_pool_size: [100]

  # Full grid search with all combinations
  full_grid_search:
    program_args:
      batch_size: 64
      user_corrected_max_per_batch: 4
      early_stopping_patience: 15
      accuracy_threshold: 0.95
      output_filename: "experiments/full_grid_search.csv"
      tensorboard_log_dir: "runs/full_grid_search"
      train_dataset_size: -1  # Use full dataset

    learning_rate: [0.01, 0.001]  # Best 2 from lr_search
    loss_type: ["balanced", "imbalanced"]
    lambda_weight: [1.0, 2.0]  # Best from lambda_search
    user_corrected_pool_size: [100, 500]  # Compare pool sizes
