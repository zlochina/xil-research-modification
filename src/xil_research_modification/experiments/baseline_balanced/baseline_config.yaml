# Configuration file for baseline loss experiments
# Supports: overfit testing, LR search, and full grid search...

general:
  # Default program arguments
  program_args:
    batch_size: 64
    user_corrected_max_per_batch: 4
    validate_ds_size: 0.4  # Fraction of test set used for validation
    early_stopping_patience: 10  # Epochs without improvement before stopping
    accuracy_threshold: 0.95  # Stop grid search if this accuracy is reached
    output_filename: "experiments/baseline_default.csv"
    tensorboard_log_dir: "runs/baseline_experiment"

  # Default hyperparameters for grid search
  learning_rate: [0.01, 0.001, 0.0001]
  loss_type: ["balanced", "imbalanced"]
  lambda_weight: [1.0]  # Weight for user-corrected samples in BaselineBalancedLoss
  user_corrected_pool_size: [100]  # Number of pre-generated corrected instances

experiments:
  # Quick sanity check: overfit on tiny dataset
  overfit_test:
    program_args:
      batch_size: 16
      user_corrected_max_per_batch: 4
      early_stopping_patience: 50  # Allow more epochs for overfitting
      accuracy_threshold: 0.99
      output_filename: "experiments/overfit_test.csv"
      tensorboard_log_dir: "runs/overfit_test"
      train_dataset_size: 100  # Use only 100 samples

    learning_rate: [0.01]
    loss_type: ["balanced", "imbalanced"]
    lambda_weight: [1.0]
    user_corrected_pool_size: [50]  # Small pool for testing

  # Find optimal learning rate with fixed other params
  lr_search:
    program_args:
      batch_size: 64
      user_corrected_max_per_batch: 4
      early_stopping_patience: 10
      accuracy_threshold: 0.95
      output_filename: "experiments/lr_search.csv"
      tensorboard_log_dir: "runs/lr_search"
      train_dataset_size: 1000  # Subset for faster iteration

    learning_rate: [0.1, 0.07, 0.05, 0.01, 0.007, 0.005, 0.001, 0.0001]
    loss_type: ["balanced"]  # Fix loss type
    lambda_weight: [1.0]  # Fix lambda
    user_corrected_pool_size: [100]

  # Search over lambda weight (for BaselineBalancedLoss)
  lambda_search:
    program_args:
      batch_size: 64
      user_corrected_max_per_batch: 4
      early_stopping_patience: 10
      accuracy_threshold: 0.95
      output_filename: "experiments/lambda_search.csv"
      tensorboard_log_dir: "runs/lambda_search"
      train_dataset_size: 1000

    learning_rate: [0.01]  # Use best LR from lr_search
    loss_type: ["balanced"]
    lambda_weight: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
    user_corrected_pool_size: [100]

  # Full grid search with all combinations
  full_grid_search:
    program_args:
      batch_size: 64
      user_corrected_max_per_batch: 4
      early_stopping_patience: 15
      accuracy_threshold: 0.95
      output_filename: "experiments/full_grid_search.csv"
      tensorboard_log_dir: "runs/full_grid_search"
      train_dataset_size: -1  # Use full dataset

    learning_rate: [0.01, 0.001]  # Best 2 from lr_search
    loss_type: ["balanced", "imbalanced"]
    lambda_weight: [1.0, 2.0]  # Best from lambda_search
    user_corrected_pool_size: [100, 500]  # Compare pool sizes